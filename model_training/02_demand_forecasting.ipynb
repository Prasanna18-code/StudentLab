{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKtWiPKrX6Ic"
      },
      "source": [
        "# Demand Forecasting with LightGBM & Optuna\n",
        "\n",
        "This notebook trains a LightGBM model to predict demand, optimized using Optuna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X0AO_Y0X6Ir",
        "outputId": "a7ec724a-205b-4be9-d1f6-ee1e27dbffc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pP6kw02fX6I8"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "df = pd.read_csv('./Dynamic-Pricing/data/sales_data.csv')\n",
        "\n",
        "# Feature Engineering\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Day'] = df['Date'].dt.day\n",
        "df['Weekday'] = df['Date'].dt.weekday\n",
        "\n",
        "# Encode Categoricals\n",
        "cat_cols = ['Store ID', 'Product ID', 'Category', 'Region', 'Weather Condition', 'Seasonality', 'Promotion']\n",
        "le_dict = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    le_dict[col] = le\n",
        "\n",
        "# Define Features and Target\n",
        "# We include Inventory Level as per RPD\n",
        "features = ['Store ID', 'Product ID', 'Category', 'Region', 'Inventory Level',\n",
        "            'Price', 'Discount', 'Weather Condition', 'Promotion',\n",
        "            'Competitor Pricing', 'Seasonality', 'Epidemic', 'Month', 'Day', 'Weekday']\n",
        "target = 'Demand'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxFBI-trX6JB"
      },
      "source": [
        "## Optuna Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 80),  # Reduced upper bound\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 7),      # Reduced upper bound\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 100), # Increased lower bound\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
        "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 1e-8, 0.1, log=True),\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMRegressor(**params)\n",
        "    model.fit(X_train, y_train,\n",
        "              eval_set=[(X_test, y_test)],\n",
        "              eval_metric='rmse',\n",
        "              callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]) # Early stopping added\n",
        "    preds = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    return rmse\n",
        "\n",
        "# Run Optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30) # Increased trials for better search with more params\n",
        "\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxO8p6UVF1Kh",
        "outputId": "4a49e7bd-8c3b-424d-ba5a-0abe88cac956"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-27 06:57:38,895] A new study created in memory with name: no-name-1d0690bb-1156-46ca-acf2-23677cf9ca9d\n",
            "[I 2025-11-27 06:57:48,070] Trial 0 finished with value: 10.522913102435256 and parameters: {'num_leaves': 53, 'learning_rate': 0.1159936482320049, 'n_estimators': 617, 'max_depth': 7, 'min_child_samples': 69, 'subsample': 0.7005390311587113, 'colsample_bytree': 0.7696175298615422, 'lambda_l1': 5.190352095688252e-05, 'lambda_l2': 7.05857565018527e-08, 'min_gain_to_split': 6.195526215332507e-05}. Best is trial 0 with value: 10.522913102435256.\n",
            "[I 2025-11-27 06:57:53,502] Trial 1 finished with value: 14.549120244729606 and parameters: {'num_leaves': 33, 'learning_rate': 0.22412995796839252, 'n_estimators': 730, 'max_depth': 4, 'min_child_samples': 20, 'subsample': 0.95465708538808, 'colsample_bytree': 0.5693318210599521, 'lambda_l1': 1.929419130595072e-07, 'lambda_l2': 5.743500777748627e-07, 'min_gain_to_split': 0.060532490583730815}. Best is trial 0 with value: 10.522913102435256.\n",
            "[I 2025-11-27 06:58:03,426] Trial 2 finished with value: 8.774470234959109 and parameters: {'num_leaves': 56, 'learning_rate': 0.15806096199928532, 'n_estimators': 726, 'max_depth': 7, 'min_child_samples': 59, 'subsample': 0.9495838366146508, 'colsample_bytree': 0.6869277670075598, 'lambda_l1': 0.5017046855826934, 'lambda_l2': 0.0006837849968829432, 'min_gain_to_split': 0.015530825565688041}. Best is trial 2 with value: 8.774470234959109.\n",
            "[I 2025-11-27 06:58:14,401] Trial 3 finished with value: 7.7437463805513715 and parameters: {'num_leaves': 42, 'learning_rate': 0.271907369781132, 'n_estimators': 774, 'max_depth': 6, 'min_child_samples': 49, 'subsample': 0.9814331046354892, 'colsample_bytree': 0.8799194096107437, 'lambda_l1': 0.009515389172839128, 'lambda_l2': 0.5556237493465229, 'min_gain_to_split': 0.004323000842254997}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:58:16,811] Trial 4 finished with value: 23.463946018767604 and parameters: {'num_leaves': 47, 'learning_rate': 0.16709062808711403, 'n_estimators': 319, 'max_depth': 4, 'min_child_samples': 26, 'subsample': 0.7748262417164482, 'colsample_bytree': 0.6717148685949863, 'lambda_l1': 2.2326228912289956, 'lambda_l2': 1.0320666816760088e-07, 'min_gain_to_split': 2.3647749545734536e-07}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:58:19,566] Trial 5 finished with value: 19.18391746691287 and parameters: {'num_leaves': 21, 'learning_rate': 0.22047484363466185, 'n_estimators': 363, 'max_depth': 4, 'min_child_samples': 37, 'subsample': 0.5733576645039458, 'colsample_bytree': 0.92374489053767, 'lambda_l1': 6.294160377561223e-08, 'lambda_l2': 2.396920413309539, 'min_gain_to_split': 1.5877574126099913e-05}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:58:22,373] Trial 6 finished with value: 16.954265319142188 and parameters: {'num_leaves': 20, 'learning_rate': 0.25913490290020824, 'n_estimators': 248, 'max_depth': 7, 'min_child_samples': 47, 'subsample': 0.8578917540711228, 'colsample_bytree': 0.5158316847775135, 'lambda_l1': 1.1791146683345714e-06, 'lambda_l2': 6.618681399773361, 'min_gain_to_split': 1.1852325561274258e-06}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:58:28,162] Trial 7 finished with value: 16.730246507693103 and parameters: {'num_leaves': 78, 'learning_rate': 0.10936974309417198, 'n_estimators': 581, 'max_depth': 5, 'min_child_samples': 64, 'subsample': 0.6622805044256375, 'colsample_bytree': 0.8870597567943521, 'lambda_l1': 0.001528780090749887, 'lambda_l2': 3.799528389458828e-07, 'min_gain_to_split': 4.4818177768774685e-08}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:58:36,469] Trial 8 finished with value: 8.197087679634137 and parameters: {'num_leaves': 45, 'learning_rate': 0.22048335126473784, 'n_estimators': 696, 'max_depth': 7, 'min_child_samples': 80, 'subsample': 0.8316314049612441, 'colsample_bytree': 0.9591266548416532, 'lambda_l1': 0.2878792191210042, 'lambda_l2': 9.892718886609145e-05, 'min_gain_to_split': 0.033885110512116665}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:58:39,377] Trial 9 finished with value: 22.363043955033877 and parameters: {'num_leaves': 40, 'learning_rate': 0.08748370274905798, 'n_estimators': 237, 'max_depth': 6, 'min_child_samples': 61, 'subsample': 0.9169568185117056, 'colsample_bytree': 0.8869482524118129, 'lambda_l1': 2.6712861463837982, 'lambda_l2': 0.07847891652465636, 'min_gain_to_split': 4.6200794407638314e-06}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:58:45,137] Trial 10 finished with value: 17.01555190634607 and parameters: {'num_leaves': 68, 'learning_rate': 0.29803666878481927, 'n_estimators': 995, 'max_depth': 3, 'min_child_samples': 97, 'subsample': 0.5261267317936145, 'colsample_bytree': 0.7961706532872092, 'lambda_l1': 0.0048019892169156265, 'lambda_l2': 0.017686792084294804, 'min_gain_to_split': 0.0005968945645962192}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:58:56,120] Trial 11 finished with value: 19.837248378563608 and parameters: {'num_leaves': 35, 'learning_rate': 0.03467911425175914, 'n_estimators': 937, 'max_depth': 6, 'min_child_samples': 85, 'subsample': 0.8294271310391684, 'colsample_bytree': 0.9930610469947896, 'lambda_l1': 0.07008475965838835, 'lambda_l2': 3.9065014400421766e-05, 'min_gain_to_split': 0.0028844236088126523}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:59:06,094] Trial 12 finished with value: 7.8727104876190666 and parameters: {'num_leaves': 45, 'learning_rate': 0.22205901612515896, 'n_estimators': 824, 'max_depth': 6, 'min_child_samples': 78, 'subsample': 0.8513338153548848, 'colsample_bytree': 0.9930961483346591, 'lambda_l1': 0.027923188107866433, 'lambda_l2': 0.00011213893776912229, 'min_gain_to_split': 0.0002881660677956825}. Best is trial 3 with value: 7.7437463805513715.\n",
            "[I 2025-11-27 06:59:15,983] Trial 13 finished with value: 7.523314207183896 and parameters: {'num_leaves': 56, 'learning_rate': 0.262554219556489, 'n_estimators': 827, 'max_depth': 6, 'min_child_samples': 47, 'subsample': 0.9933100235550383, 'colsample_bytree': 0.8385903458511682, 'lambda_l1': 5.071278172776188e-05, 'lambda_l2': 0.004530558997684652, 'min_gain_to_split': 0.00027549136070056127}. Best is trial 13 with value: 7.523314207183896.\n",
            "[I 2025-11-27 06:59:23,783] Trial 14 finished with value: 7.850337049203401 and parameters: {'num_leaves': 61, 'learning_rate': 0.2728092249221265, 'n_estimators': 853, 'max_depth': 5, 'min_child_samples': 46, 'subsample': 0.9899056559182637, 'colsample_bytree': 0.833941725612571, 'lambda_l1': 4.419841411434438e-05, 'lambda_l2': 0.056983719499107584, 'min_gain_to_split': 0.0028225898177541772}. Best is trial 13 with value: 7.523314207183896.\n",
            "[I 2025-11-27 06:59:29,739] Trial 15 finished with value: 10.849614128629428 and parameters: {'num_leaves': 66, 'learning_rate': 0.2651543441517464, 'n_estimators': 464, 'max_depth': 5, 'min_child_samples': 47, 'subsample': 0.9045709123459779, 'colsample_bytree': 0.8399764784923242, 'lambda_l1': 8.679472339454797e-05, 'lambda_l2': 0.0069388945852424016, 'min_gain_to_split': 0.00021245127316645067}. Best is trial 13 with value: 7.523314207183896.\n",
            "[I 2025-11-27 06:59:37,733] Trial 16 finished with value: 8.490806282361731 and parameters: {'num_leaves': 31, 'learning_rate': 0.19197006300777003, 'n_estimators': 843, 'max_depth': 6, 'min_child_samples': 35, 'subsample': 0.9954629206894804, 'colsample_bytree': 0.6899841569477336, 'lambda_l1': 8.61190268258104e-06, 'lambda_l2': 0.420014811845385, 'min_gain_to_split': 0.004238978995921457}. Best is trial 13 with value: 7.523314207183896.\n",
            "[I 2025-11-27 06:59:44,381] Trial 17 finished with value: 8.480154875653783 and parameters: {'num_leaves': 74, 'learning_rate': 0.29795229533459144, 'n_estimators': 498, 'max_depth': 6, 'min_child_samples': 55, 'subsample': 0.7623308505533151, 'colsample_bytree': 0.7360658603518869, 'lambda_l1': 0.0009280779854796471, 'lambda_l2': 0.0021018931354418557, 'min_gain_to_split': 3.7625439279111296e-05}. Best is trial 13 with value: 7.523314207183896.\n",
            "[I 2025-11-27 06:59:53,772] Trial 18 finished with value: 7.4680442446075235 and parameters: {'num_leaves': 57, 'learning_rate': 0.2520559724919337, 'n_estimators': 798, 'max_depth': 6, 'min_child_samples': 36, 'subsample': 0.9145932993569705, 'colsample_bytree': 0.8493842711730285, 'lambda_l1': 0.011129967708279696, 'lambda_l2': 7.308657803704824e-06, 'min_gain_to_split': 0.0011574157632578764}. Best is trial 18 with value: 7.4680442446075235.\n",
            "[I 2025-11-27 07:00:02,967] Trial 19 finished with value: 9.126192154038817 and parameters: {'num_leaves': 59, 'learning_rate': 0.1935267569754262, 'n_estimators': 919, 'max_depth': 5, 'min_child_samples': 35, 'subsample': 0.8986318422515969, 'colsample_bytree': 0.8147173942657172, 'lambda_l1': 0.0002926124813652527, 'lambda_l2': 1.5356613562385682e-05, 'min_gain_to_split': 0.000712933014005596}. Best is trial 18 with value: 7.4680442446075235.\n",
            "[I 2025-11-27 07:00:07,953] Trial 20 finished with value: 21.184943071493585 and parameters: {'num_leaves': 65, 'learning_rate': 0.24831130497743079, 'n_estimators': 637, 'max_depth': 3, 'min_child_samples': 27, 'subsample': 0.6501371416286091, 'colsample_bytree': 0.7532018859465959, 'lambda_l1': 2.776503818128089e-06, 'lambda_l2': 4.211039738182306e-06, 'min_gain_to_split': 4.748114094642213e-06}. Best is trial 18 with value: 7.4680442446075235.\n",
            "[I 2025-11-27 07:00:17,393] Trial 21 finished with value: 7.618017882927323 and parameters: {'num_leaves': 55, 'learning_rate': 0.2777540289811802, 'n_estimators': 751, 'max_depth': 6, 'min_child_samples': 41, 'subsample': 0.9499060370344565, 'colsample_bytree': 0.8882801185807183, 'lambda_l1': 0.008393464983835197, 'lambda_l2': 0.3606960637974332, 'min_gain_to_split': 0.007187944837922281}. Best is trial 18 with value: 7.4680442446075235.\n",
            "[I 2025-11-27 07:00:18,947] Trial 22 finished with value: 18.460300133988948 and parameters: {'num_leaves': 52, 'learning_rate': 0.2447271702656693, 'n_estimators': 122, 'max_depth': 6, 'min_child_samples': 40, 'subsample': 0.9275216016896662, 'colsample_bytree': 0.9337133311915633, 'lambda_l1': 0.07691117695792671, 'lambda_l2': 2.592953075158405e-06, 'min_gain_to_split': 0.011483971334759369}. Best is trial 18 with value: 7.4680442446075235.\n",
            "[I 2025-11-27 07:00:29,679] Trial 23 finished with value: 7.437366295007144 and parameters: {'num_leaves': 58, 'learning_rate': 0.29438140825864795, 'n_estimators': 898, 'max_depth': 7, 'min_child_samples': 29, 'subsample': 0.8759658641889436, 'colsample_bytree': 0.8649877113697548, 'lambda_l1': 0.0022864899234097216, 'lambda_l2': 0.0011510114806465618, 'min_gain_to_split': 0.0001501414241658878}. Best is trial 23 with value: 7.437366295007144.\n",
            "[I 2025-11-27 07:00:41,531] Trial 24 finished with value: 7.724454144776074 and parameters: {'num_leaves': 72, 'learning_rate': 0.29716315511687497, 'n_estimators': 914, 'max_depth': 7, 'min_child_samples': 21, 'subsample': 0.8696037805301707, 'colsample_bytree': 0.8496543819064165, 'lambda_l1': 0.00036920989245233394, 'lambda_l2': 0.0019047008477197425, 'min_gain_to_split': 0.00012170601343230018}. Best is trial 23 with value: 7.437366295007144.\n",
            "[I 2025-11-27 07:00:53,800] Trial 25 finished with value: 7.258088300595027 and parameters: {'num_leaves': 60, 'learning_rate': 0.23848790736922298, 'n_estimators': 999, 'max_depth': 7, 'min_child_samples': 29, 'subsample': 0.7976124082707466, 'colsample_bytree': 0.7832127167237855, 'lambda_l1': 0.0023311150228052316, 'lambda_l2': 0.0005437083199334492, 'min_gain_to_split': 0.0010777530363042587}. Best is trial 25 with value: 7.258088300595027.\n",
            "[I 2025-11-27 07:01:06,366] Trial 26 finished with value: 7.243309139613637 and parameters: {'num_leaves': 62, 'learning_rate': 0.19262964685474476, 'n_estimators': 991, 'max_depth': 7, 'min_child_samples': 28, 'subsample': 0.7989217603734662, 'colsample_bytree': 0.7845896519997099, 'lambda_l1': 0.002042592105482397, 'lambda_l2': 0.00039961411906077417, 'min_gain_to_split': 0.0010962485070004965}. Best is trial 26 with value: 7.243309139613637.\n",
            "[I 2025-11-27 07:01:18,872] Trial 27 finished with value: 7.48891252124446 and parameters: {'num_leaves': 63, 'learning_rate': 0.20435971934266653, 'n_estimators': 991, 'max_depth': 7, 'min_child_samples': 28, 'subsample': 0.7215214467666564, 'colsample_bytree': 0.6301777619354835, 'lambda_l1': 0.001742541819334789, 'lambda_l2': 0.000383150667806652, 'min_gain_to_split': 1.3726840130011997e-05}. Best is trial 26 with value: 7.243309139613637.\n",
            "[I 2025-11-27 07:01:31,274] Trial 28 finished with value: 7.5589998844390065 and parameters: {'num_leaves': 71, 'learning_rate': 0.17549818087763247, 'n_estimators': 900, 'max_depth': 7, 'min_child_samples': 31, 'subsample': 0.7862653866111539, 'colsample_bytree': 0.7190111532320531, 'lambda_l1': 0.000470544716780179, 'lambda_l2': 0.0002988566790861148, 'min_gain_to_split': 0.0012718945932804052}. Best is trial 26 with value: 7.243309139613637.\n",
            "[I 2025-11-27 07:01:44,527] Trial 29 finished with value: 7.883567554058396 and parameters: {'num_leaves': 50, 'learning_rate': 0.13721678348848462, 'n_estimators': 990, 'max_depth': 7, 'min_child_samples': 24, 'subsample': 0.804507143318823, 'colsample_bytree': 0.7751016956357921, 'lambda_l1': 1.1761849311816744e-05, 'lambda_l2': 0.02030663870360682, 'min_gain_to_split': 7.457770010278781e-05}. Best is trial 26 with value: 7.243309139613637.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: {'num_leaves': 62, 'learning_rate': 0.19262964685474476, 'n_estimators': 991, 'max_depth': 7, 'min_child_samples': 28, 'subsample': 0.7989217603734662, 'colsample_bytree': 0.7845896519997099, 'lambda_l1': 0.002042592105482397, 'lambda_l2': 0.00039961411906077417, 'min_gain_to_split': 0.0010962485070004965}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qH3jiExhX6JE"
      },
      "outputs": [],
      "source": [
        "# def objective(trial):\n",
        "#     params = {\n",
        "#         'objective': 'regression',\n",
        "#         'metric': 'rmse',\n",
        "#         'verbosity': -1,\n",
        "#         'boosting_type': 'gbdt',\n",
        "#         'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "#         'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "#         'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
        "#         'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
        "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "#     }\n",
        "\n",
        "#     model = lgb.LGBMRegressor(**params)\n",
        "#     model.fit(X_train, y_train)\n",
        "#     preds = model.predict(X_test)\n",
        "#     rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "#     return rmse\n",
        "\n",
        "# # Run Optimization\n",
        "# study = optuna.create_study(direction='minimize')\n",
        "# study.optimize(objective, n_trials=20) # 20 trials for speed, increase for better results\n",
        "\n",
        "# print('Best trial:', study.best_trial.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGsLP6AjX6JH"
      },
      "source": [
        "## Train Best Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_trial.params\n",
        "best_params['objective'] = 'regression'\n",
        "best_params['metric'] = 'rmse'\n",
        "\n",
        "final_model = lgb.LGBMRegressor(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = final_model.predict(X_test)\n",
        "y_pred_train = final_model.predict(X_train)\n",
        "\n",
        "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"Test MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"Test R2:\", r2_score(y_test, y_pred))\n",
        "\n",
        "print(\"\\nTrain RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
        "print(\"Train R2:\", r2_score(y_train, y_pred_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLwMmDqCIlBI",
        "outputId": "82067e9b-325c-4a63-a465-d2503d8c81ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 7.243309139613637\n",
            "Test MAE: 4.772434998443257\n",
            "Test R2: 0.976243987765607\n",
            "\n",
            "Train RMSE: 3.7729675441230794\n",
            "Train R2: 0.9935439437501788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecZ7ux_fX6JN",
        "outputId": "45d29a7c-15bb-4000-dce9-aab5d614ca05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 7.243309139613637\n",
            "MAE: 4.772434998443257\n",
            "R2: 0.976243987765607\n"
          ]
        }
      ],
      "source": [
        "best_params = study.best_trial.params\n",
        "best_params['objective'] = 'regression'\n",
        "best_params['metric'] = 'rmse'\n",
        "\n",
        "final_model = lgb.LGBMRegressor(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"R2:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIY54O2OX6JR"
      },
      "source": [
        "## Save Model and Encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pZwByqMX6JV",
        "outputId": "2c89114a-0d59-43cd-c9eb-c98383234946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and encoders saved.\n"
          ]
        }
      ],
      "source": [
        "with open('demand_model_lgbm.pkl', 'wb') as f:\n",
        "    pickle.dump(final_model, f)\n",
        "\n",
        "with open('label_encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(le_dict, f)\n",
        "\n",
        "print(\"Model and encoders saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua7ihc9XX6Je",
        "outputId": "be9e02b4-1b9d-43c1-eaf6-b57a44a795e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dynamic-Pricing'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 103 (delta 19), reused 86 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (103/103), 9.80 MiB | 18.27 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PraveenDevamane/Dynamic-Pricing.git"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}